apiVersion: v1
kind: Service
metadata:
  namespace: monitoring
  name: prometheus-service
spec:
  selector:
    app: prometheus
  ports:
  - protocol: TCP
    port: 9090
    targetPort: 9090
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-deployment
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus
        volumeMounts:
          - name: config-volume
            mountPath: /etc/prometheus/prometheus.yml
            subPath: prometheus.yaml
          - name: config-volume
            mountPath: /etc/prometheus/prometheus.rules
            subPath: prometheus.rules
          - name: prometheus-storage-volume
            mountPath: /prometheus/
        ports:
        - containerPort: 9090
      volumes:
        - name: config-volume
          configMap:
            name: prometheus-config
        - name: prometheus-storage-volume
          persistentVolumeClaim:
            claimName: prometheus-pv-claim
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-pv-claim
  labels:
    app: prometheus
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: default
  namespace: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.rules: |-
    groups:
    - name: cluster ressources
      rules:
      - alert: CPU minimum usage over 50%
        expr: |
          sum(kube_pod_container_resource_requests{resource="cpu"})/ sum(kube_node_status_allocatable{resource="cpu"}) * 100 > 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: CPU minimum usage {{ printf "%0.0f" $value }}%.
      - alert: CPU minimum usage over 70%
        expr: |
          sum(kube_pod_container_resource_requests{resource="cpu"})/ sum(kube_node_status_allocatable{resource="cpu"}) * 100 > 70
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: CPU minimum usage {{ printf "%0.0f" $value }}%.
      - alert: Memory minimum usage over 50%
        expr: |
          sum(kube_pod_container_resource_requests{resource="memory"})/ sum(kube_node_status_allocatable{resource="memory"}) * 100 > 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: RAM minimum usage {{ printf "%0.0f" $value }}%.
      - alert: Memory minimum usage over 70%
        expr: |
          sum(kube_pod_container_resource_requests{resource="memory"})/ sum(kube_node_status_allocatable{resource="memory"}) * 100 > 70
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: RAM minimum usage {{ printf "%0.0f" $value }}%.
      - alert: Cluster load over 50%
        expr: |
          sum(node_load1) / count(count(node_cpu_seconds_total{job="node-exporter"}) by (cpu)) * 100 > 50
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: Cluster load is currently {{ printf "%0.0f" $value }}%.
      - alert: Cluster load over 90%
        expr: |
          sum(node_load1) / count(count(node_cpu_seconds_total{job="node-exporter"}) by (cpu)) * 100 > 90
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: Cluster load is currently {{ printf "%0.0f" $value }}%.
    - name: metrics
      rules:
      - alert: KubeStateMetricsDown
        annotations:
          summary: KubeStateMetrics has disappeared from Prometheus target discovery.
        expr: |
          absent(up{job="kube-state-metrics"} == 1)
        for: 15m
        labels:
          severity: critical
      - alert: NodeExporterDown
        annotations:
          summary: NodeExporter has disappeared from Prometheus target discovery.
        expr: |
          absent(up{job="node-exporter"} == 1)
        for: 15m
        labels:
          severity: critical
    - name: Kube app
      rules:
      - alert: Pod Crash Looping
        annotations:
          summary: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
            }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
        expr: |
          rate(kube_pod_container_status_restarts_total{job="kube-state-metrics"}[15m]) * 60 * 5 > 0
        for: 1h
        labels:
          severity: critical
      - alert: Deployment Replicas Mismatch
        annotations:
          summary: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not
            matched the expected number of replicas for longer than an hour.
        expr: |
          kube_deployment_spec_replicas{job="kube-state-metrics"}
            !=
          kube_deployment_status_replicas_available{job="kube-state-metrics"}
        for: 1h
        labels:
          severity: critical
      - alert: Stateful Set Replicas Mismatch
        annotations:
          summary: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has
            not matched the expected number of replicas for longer than 15 minutes.
        expr: |
          kube_statefulset_status_replicas_ready{job="kube-state-metrics"}
            !=
          kube_statefulset_status_replicas{job="kube-state-metrics"}
        for: 15m
        labels:
          severity: critical
      - alert: DaemonSet Rollout Stuck
        annotations:
          summary: Only {{ $value }}% of the desired Pods of DaemonSet {{ $labels.namespace
            }}/{{ $labels.daemonset }} are scheduled and ready.
        expr: |
          kube_daemonset_status_number_ready{job="kube-state-metrics"}
            /
          kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} * 100 < 100
        for: 15m
        labels:
          severity: critical
  prometheus.yaml: |
    global:
      scrape_interval:     15s
      external_labels:
        monitor: 'k3s-monitor'
    rule_files:
      - /etc/prometheus/prometheus.rules
    scrape_configs:
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
        - source_labels: [__meta_kubernetes_endpoints_name]
          regex: 'node-exporter'
          action: keep
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics.kube-system.svc.cluster.local:8080', 'kube-state-metrics.kube-system.svc.cluster.local:8081']
      - job_name: 'traefik-metrics'
        static_configs:
          - targets: ['traefik-metrics.kube-system.svc.cluster.local:9100']
